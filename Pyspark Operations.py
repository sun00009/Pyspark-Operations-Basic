# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FwKmmCyIqbBCzzLlPju7Fj0Zbq6WlD2F
"""

pip install pyspark

pip install sparknlp

import pyspark
import sparknlp
import pyspark.sql.functions as f

# Start the spark session
spark = sparknlp.start()

# Read csv files with spark
data_1 = spark.read.option('Header',True).csv('/content/product.csv')
data_2 = spark.read.option('Header',True).csv('/content/transaction.csv')

# Basic join operation
data_3 = data_1.join(data_2,data_1.customer_id==data_2.customer_id)

# Creating column within the dataframe
data_3 = data_3.withColumnRenamed('color','color_unique')

# Checking your data
data_3.show()

# Looking into mean of data
data_3.agg({'purchased_quantity':'mean'}).collect()

# Selecting columns
data_3.select('color_unique','product_id').show()

# Pivot the table based on specific data
data_4 = data_3.groupBy('transaction_date').pivot('color_unique').agg(f.first('purchased_quantity'))

data_4.show()

data_6 = data_4.select('transaction_date','black')

# Filling NA
data_6.fillna({'black':0}).show()



